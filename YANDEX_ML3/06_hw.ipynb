{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dda9a7f",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1fba2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.optimize import minimize\n",
    "import itertools\n",
    "import csv\n",
    "import warnings\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_DIR =  './best_pictures'\n",
    "KNOWN_FILTERS_FILE = os.path.join(DATA_DIR, 'algos.csv')\n",
    "OUTPUT_CSV_FILE = 'reconstructed_algos.csv'\n",
    "\n",
    "# можно увеличить для большей точности\n",
    "MAX_PAIRS_FOR_OPTIMIZATION = 10\n",
    "\n",
    "MAXITER = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80a3c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_known_filters(filepath):\n",
    "    \"\"\"Загружает известные фильтры из CSV файла.\"\"\"\n",
    "    try:\n",
    "        filters_flat = np.loadtxt(filepath, delimiter=',')\n",
    "        if filters_flat.shape != (2, 9):\n",
    "            raise ValueError(\"CSV файл должен содержать ровно 2 строки по 9 чисел.\")\n",
    "        # Преобразуем в формат 3x3\n",
    "        filters = [f.reshape(3, 3) for f in filters_flat]\n",
    "        print(f\"Загружены 2 известных фильтра из {filepath}\")\n",
    "        return filters\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке известных фильтров из {filepath}: {e}\")\n",
    "        print(\"Убедитесь, что файл существует и имеет правильный формат.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d9daa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_output_pairs(data_dir):\n",
    "    \"\"\"Находит пары файлов входного изображения (.png) и выходной матрицы (.txt).\"\"\"\n",
    "    pairs = []\n",
    "    files = os.listdir(data_dir)\n",
    "    png_files = sorted([f for f in files if f.lower().endswith('.png')])\n",
    "    for png_file in png_files:\n",
    "        base_name = os.path.splitext(png_file)[0]\n",
    "        txt_file = base_name + '.txt'\n",
    "        if txt_file in files:\n",
    "            pairs.append({\n",
    "                'image': os.path.join(data_dir, png_file),\n",
    "                'output': os.path.join(data_dir, txt_file)\n",
    "            })\n",
    "    print(f\"Найдено {len(pairs)} пар вход/выход.\")\n",
    "    if not pairs:\n",
    "        print(f\"В папке {data_dir} не найдено пар .png/.txt файлов.\")\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "25545a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_grayscale(filepath):\n",
    "    \"\"\"Загружает изображение и конвертирует в одноканальный numpy массив (float).\"\"\"\n",
    "    try:\n",
    "        img = Image.open(filepath).convert('L') # 'L' для grayscale\n",
    "        return np.array(img, dtype=np.float64)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке изображения {filepath}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75f1931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_output_matrix(filepath):\n",
    "    \"\"\"Загружает выходную матрицу из .txt файла.\"\"\"\n",
    "    try:\n",
    "        return np.loadtxt(filepath, dtype=np.float64)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке выходной матрицы {filepath}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fddcce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(y_true, y_pred):\n",
    "    \"\"\"Рассчитывает среднеквадратичную ошибку.\"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "05fbbdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Начало восстановления KaiNet ---\n",
      "Загружены 2 известных фильтра из ./best_pictures\\algos.csv\n",
      "Найдено 1000 пар вход/выход.\n",
      "Загрузка данных для оптимизации (макс. 10 пар)...\n",
      "  Загружена пара: 1.png / 1.txt\n",
      "  Загружена пара: 10.png / 10.txt\n",
      "  Загружена пара: 100.png / 100.txt\n",
      "  Загружена пара: 1000.png / 1000.txt\n",
      "  Загружена пара: 101.png / 101.txt\n",
      "  Загружена пара: 102.png / 102.txt\n",
      "  Загружена пара: 103.png / 103.txt\n",
      "  Загружена пара: 104.png / 104.txt\n",
      "  Загружена пара: 105.png / 105.txt\n",
      "  Загружена пара: 106.png / 106.txt\n",
      "\n",
      "Начинаем проверку 6 возможных порядков фильтров...\n",
      "\n",
      "--- Проверка порядка #1: F1 -> F2 -> F_unknown ---\n",
      "  Запуск оптимизации (Nelder-Mead) для поиска неизвестного фильтра...\n",
      "  Оптимизация завершена. Минимальный MSE для этого порядка: 924.27540598\n",
      "  *** Найден новый лучший результат! ***\n",
      "\n",
      "--- Проверка порядка #2: F1 -> F_unknown -> F2 ---\n",
      "  Запуск оптимизации (Nelder-Mead) для поиска неизвестного фильтра...\n",
      "  Оптимизация завершена. Минимальный MSE для этого порядка: 959.39239255\n",
      "\n",
      "--- Проверка порядка #3: F2 -> F1 -> F_unknown ---\n",
      "  Запуск оптимизации (Nelder-Mead) для поиска неизвестного фильтра...\n",
      "  Оптимизация завершена. Минимальный MSE для этого порядка: 44.23346540\n",
      "  *** Найден новый лучший результат! ***\n",
      "\n",
      "--- Проверка порядка #4: F2 -> F_unknown -> F1 ---\n",
      "  Запуск оптимизации (Nelder-Mead) для поиска неизвестного фильтра...\n",
      "  Оптимизация завершена. Минимальный MSE для этого порядка: 0.00000000\n",
      "  *** Найден новый лучший результат! ***\n",
      "\n",
      "--- Проверка порядка #5: F_unknown -> F1 -> F2 ---\n",
      "  Запуск оптимизации (Nelder-Mead) для поиска неизвестного фильтра...\n",
      "  Оптимизация завершена. Минимальный MSE для этого порядка: 555.89577647\n",
      "\n",
      "--- Проверка порядка #6: F_unknown -> F2 -> F1 ---\n",
      "  Запуск оптимизации (Nelder-Mead) для поиска неизвестного фильтра...\n",
      "  Оптимизация завершена. Минимальный MSE для этого порядка: 0.00000000\n",
      "\n",
      "--- Результаты реконструкции ---\n",
      "Найден лучший порядок фильтров: F2 -> F_unknown -> F1\n",
      "Минимальное среднее MSE: 0.00000000\n",
      "Найденный неизвестный фильтр (F_unknown):\n",
      "[[0.125 0.25  0.125]\n",
      " [0.25  0.5   0.25 ]\n",
      " [0.125 0.25  0.125]]\n",
      "\n",
      "Сохранение восстановленных фильтров в файл: reconstructed_algos.csv\n",
      "Файл успешно сохранен.\n",
      "\n",
      "Содержимое файла (первые 3 строки):\n",
      "0.0625,0.0625,0.0625,0.0625,0.0625,0.0625,0.0625,0.0625,0.0625\n",
      "0.12500004,0.24999979,0.12500022,0.25000004,0.50000001,0.24999986,0.12499996,0.25000012,0.12499997\n",
      "-1.0,-0.5,0.0,-0.5,0.5,0.5,0.0,0.5,1.0\n",
      "\n",
      "--- Завершение работы ---\n"
     ]
    }
   ],
   "source": [
    "# --- Helper Functions ---\n",
    "def apply_filter(image, kernel):\n",
    "    \"\"\"\n",
    "    Применяет фильтр 3x3 к изображению методом скользящего окна.\n",
    "    Использует 'valid' свертку (без дополнения краев).\n",
    "    \"\"\"\n",
    "    # Убедимся, что ядро имеет правильную форму\n",
    "    if kernel.shape != (3, 3):\n",
    "        raise ValueError(\"Ядро фильтра должно быть размером 3x3\")\n",
    "    # scipy.signal.convolve2d с mode='valid' делает то, что нужно:\n",
    "    # поэлементное произведение окна и фильтра -> сумма\n",
    "    # Важно: переворачиваем ядро, т.к. convolve2d выполняет свертку,\n",
    "    # а в описании задачи - корреляция (или свертка с перевернутым ядром).\n",
    "    # Для симметричных ядер это не имеет значения, но лучше сделать правильно.\n",
    "    return convolve2d(image, np.rot90(kernel, 2), mode='same')\n",
    "\n",
    "def apply_sequence(image, filters):\n",
    "    \"\"\"Последовательно применяет список фильтров к изображению.\"\"\"\n",
    "    current_image = image.copy()\n",
    "    for f in filters:\n",
    "        current_image = apply_filter(current_image, f)\n",
    "    return current_image\n",
    "\n",
    "\n",
    "\n",
    "# --- Основная логика ---\n",
    "\n",
    "def reconstruct_kainet(data_dir, known_filters_file, output_csv_file):\n",
    "    \"\"\"\n",
    "    Главная функция для восстановления фильтров KaiNet.\n",
    "    \"\"\"\n",
    "    print(\"--- Начало восстановления KaiNet ---\")\n",
    "\n",
    "    # 1. Загрузка известных фильтров\n",
    "    known_filters = load_known_filters(known_filters_file)\n",
    "    if known_filters is None:\n",
    "        return\n",
    "    f1, f2 = known_filters\n",
    "\n",
    "    # 2. Поиск и загрузка данных (ограниченное количество пар)\n",
    "    image_output_pairs = find_image_output_pairs(data_dir)\n",
    "    if not image_output_pairs:\n",
    "        return\n",
    "\n",
    "    loaded_data = []\n",
    "    print(f\"Загрузка данных для оптимизации (макс. {MAX_PAIRS_FOR_OPTIMIZATION} пар)...\")\n",
    "    for i, pair in enumerate(image_output_pairs):\n",
    "        if i >= MAX_PAIRS_FOR_OPTIMIZATION:\n",
    "            break\n",
    "        img = load_image_grayscale(pair['image'])\n",
    "        output_matrix = load_output_matrix(pair['output'])\n",
    "\n",
    "        if img is not None and output_matrix is not None:\n",
    "            loaded_data.append({'image': img, 'output': output_matrix})\n",
    "            print(f\"  Загружена пара: {os.path.basename(pair['image'])} / {os.path.basename(pair['output'])}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"  Пропуск пары из-за ошибки загрузки.\")\n",
    "\n",
    "    if not loaded_data:\n",
    "        print(\"Не удалось загрузить ни одной валидной пары вход/выход для оптимизации. Прерывание.\")\n",
    "        return\n",
    "\n",
    "    # 3. Перебор перестановок и оптимизация\n",
    "    filters_to_permute = [f1, f2, 'unknown'] # Метка для неизвестного фильтра\n",
    "    possible_permutations = list(itertools.permutations(filters_to_permute))\n",
    "    print(f\"\\nНачинаем проверку {len(possible_permutations)} возможных порядков фильтров...\")\n",
    "\n",
    "    best_result = {\n",
    "        'final_filters': None, # Сохраняем итоговый набор фильтров\n",
    "        'unknown_filter': None,\n",
    "        'mse': float('inf'),\n",
    "        'order_description': None\n",
    "    }\n",
    "\n",
    "    # Используем метод оптимизации, который не требует градиентов (может быть медленнее, но проще)\n",
    "    # 'Nelder-Mead' - хороший выбор для начала.\n",
    "    optimization_method = 'Nelder-Mead'\n",
    "    # Начальное предположение для неизвестного фильтра (9 значений) - нули\n",
    "    initial_guess_unknown = np.zeros(9)\n",
    "\n",
    "    for i, permutation in enumerate(possible_permutations):\n",
    "        # Создаем читаемое описание порядка для вывода\n",
    "        order_desc_list = []\n",
    "        known_filter_indices = {id(f1): 'F1', id(f2): 'F2'} # Используем id для различения f1 и f2\n",
    "        for item in permutation:\n",
    "            if isinstance(item, str) and item == 'unknown':\n",
    "                order_desc_list.append('F_unknown')\n",
    "            elif id(item) in known_filter_indices:\n",
    "                 order_desc_list.append(known_filter_indices[id(item)])\n",
    "            else:\n",
    "                 order_desc_list.append('?') # На всякий случай\n",
    "        order_description_str = \" -> \".join(order_desc_list)\n",
    "\n",
    "        print(f\"\\n--- Проверка порядка #{i+1}: {order_description_str} ---\")\n",
    "\n",
    "\n",
    "        # Функция потерь для оптимизатора\n",
    "        def loss_function(unknown_filter_flat):\n",
    "            unknown_filter_matrix = unknown_filter_flat.reshape(3, 3)\n",
    "            current_mse_sum = 0\n",
    "            num_valid_pairs = 0\n",
    "\n",
    "            # Собираем полный список фильтров для этой перестановки\n",
    "            current_filter_sequence = []\n",
    "            for item in permutation:\n",
    "                # *** ИСПРАВЛЕНИЕ ЗДЕСЬ ***\n",
    "                # Проверяем, является ли item строкой 'unknown'\n",
    "                if isinstance(item, str) and item == 'unknown':\n",
    "                    current_filter_sequence.append(unknown_filter_matrix)\n",
    "                else:\n",
    "                    # Иначе это должен быть один из известных фильтров (NumPy array)\n",
    "                    current_filter_sequence.append(item)\n",
    "\n",
    "            # Считаем MSE по всем загруженным парам\n",
    "            for data_pair in loaded_data:\n",
    "                input_img = data_pair['image']\n",
    "                target_output = data_pair['output']\n",
    "\n",
    "                # Применяем последовательность фильтров\n",
    "                try:\n",
    "                    calculated_output = apply_sequence(input_img, current_filter_sequence)\n",
    "\n",
    "                    # Проверяем совпадение размеров выхода (хотя уже проверили при загрузке)\n",
    "                    if calculated_output.shape != target_output.shape:\n",
    "                        warnings.warn(f\"Размер вычисленного выхода {calculated_output.shape} \"\n",
    "                                      f\"не совпадает с целевым {target_output.shape} для порядка {order_description_str}. \"\n",
    "                                      f\"Это не должно было произойти. Пропуск пары.\")\n",
    "                        continue\n",
    "\n",
    "                    current_mse_sum += calculate_mse(target_output, calculated_output)\n",
    "                    num_valid_pairs += 1\n",
    "                except Exception as e:\n",
    "                     # Добавим больше деталей в сообщение об ошибке\n",
    "                     warnings.warn(f\"Ошибка при применении фильтров для порядка {order_description_str} \"\n",
    "                                   f\"на изображении {data_pair.get('image_path', 'N/A')}: {e}. Пропуск пары.\")\n",
    "                     continue\n",
    "\n",
    "            if num_valid_pairs == 0:\n",
    "                 warnings.warn(f\"Не удалось вычислить MSE ни для одной пары для порядка {order_description_str}.\")\n",
    "                 return float('inf') # Возвращаем бесконечность, если ни одна пара не сработала\n",
    "\n",
    "            average_mse = current_mse_sum / num_valid_pairs\n",
    "            # print(f\"    Текущий MSE: {average_mse:.6f}\") # Отладочный вывод (может быть много)\n",
    "            return average_mse\n",
    "\n",
    "        # Запускаем оптимизацию для поиска лучшего unknown_filter для этого порядка\n",
    "        print(f\"  Запуск оптимизации ({optimization_method}) для поиска неизвестного фильтра...\")\n",
    "        opt_result = minimize(loss_function,\n",
    "                              initial_guess_unknown,\n",
    "                              method=optimization_method,\n",
    "                              options={'maxiter': MAXITER, 'adaptive': True, 'fatol': 1e-6, 'xatol': 1e-6}) # Увеличим maxiter и добавим tolerance\n",
    "\n",
    "        if opt_result.success or 'converged' in opt_result.message.lower(): # Считаем схождение тоже успехом\n",
    "            found_unknown_filter = opt_result.x.reshape(3, 3)\n",
    "            final_mse = opt_result.fun\n",
    "            print(f\"  Оптимизация завершена. Минимальный MSE для этого порядка: {final_mse:.8f}\")\n",
    "            if not opt_result.success:\n",
    "                 print(f\"  (Примечание: Оптимизация формально не 'успешна', но сошлась: {opt_result.message})\")\n",
    "\n",
    "\n",
    "            # Обновляем лучший результат, если текущий лучше\n",
    "            if final_mse < best_result['mse']:\n",
    "                print(f\"  *** Найден новый лучший результат! ***\")\n",
    "                best_result['mse'] = final_mse\n",
    "                best_result['unknown_filter'] = found_unknown_filter\n",
    "                best_result['order_description'] = order_description_str # Сохраняем читаемое описание\n",
    "                # Сохраняем реальные фильтры в найденном порядке\n",
    "                final_order_filters = []\n",
    "                for item in permutation:\n",
    "                   if isinstance(item, str) and item == 'unknown':\n",
    "                       final_order_filters.append(found_unknown_filter)\n",
    "                   else:\n",
    "                       final_order_filters.append(item)\n",
    "                best_result['final_filters'] = final_order_filters\n",
    "\n",
    "        else:\n",
    "            print(f\"  Оптимизация не сошлась для этого порядка. Причина: {opt_result.message}\")\n",
    "\n",
    "    # 4. Вывод и сохранение результата\n",
    "    print(\"\\n--- Результаты реконструкции ---\")\n",
    "    if best_result['final_filters'] is not None:\n",
    "        print(f\"Найден лучший порядок фильтров: {best_result['order_description']}\")\n",
    "        print(f\"Минимальное среднее MSE: {best_result['mse']:.8f}\")\n",
    "        print(\"Найденный неизвестный фильтр (F_unknown):\")\n",
    "        # Используем printoptions для красивого вывода матрицы\n",
    "        with np.printoptions(precision=6, suppress=True):\n",
    "             print(best_result['unknown_filter'])\n",
    "\n",
    "        # Сохраняем все три фильтра в правильном порядке\n",
    "        print(f\"\\nСохранение восстановленных фильтров в файл: {output_csv_file}\")\n",
    "        try:\n",
    "            with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                for f in best_result['final_filters']:\n",
    "                    # Сохраняем как строку из 9 чисел\n",
    "                    writer.writerow(np.round(f.flatten(), 8)) # Сохраняем с некоторой точностью\n",
    "            print(\"Файл успешно сохранен.\")\n",
    "            print(\"\\nСодержимое файла (первые 3 строки):\")\n",
    "            with open(output_csv_file, 'r') as f:\n",
    "                for i, line in enumerate(f):\n",
    "                    if i >= 3: break\n",
    "                    print(line.strip())\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при сохранении файла {output_csv_file}: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Не удалось найти решение. Возможно, стоит попробовать:\")\n",
    "        print(\"- Увеличить MAX_PAIRS_FOR_OPTIMIZATION (если есть больше пар).\")\n",
    "        print(\"- Попробовать другие методы оптимизации ('BFGS', 'CG', 'L-BFGS-B').\")\n",
    "        print(\"- Попробовать другие начальные приближения для 'initial_guess_unknown'.\")\n",
    "        print(\"- Увеличить 'maxiter' или изменить параметры 'fatol'/'xatol' в опциях оптимизатора.\")\n",
    "        print(\"- Проверить правильность путей к данным и формат файлов.\")\n",
    "\n",
    "    print(\"\\n--- Завершение работы ---\")\n",
    "\n",
    "# --- Запуск ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Проверка существования директории с данными\n",
    "    if not os.path.isdir(DATA_DIR):\n",
    "         print(f\"Ошибка: Директория с данными '{DATA_DIR}' не найдена.\")\n",
    "         print(\"Пожалуйста, создайте эту директорию, распакуйте в нее архив\")\n",
    "         print(f\"и измените переменную DATA_DIR в скрипте, если нужно.\")\n",
    "    elif not os.path.isfile(KNOWN_FILTERS_FILE):\n",
    "         print(f\"Ошибка: Файл с известными фильтрами '{KNOWN_FILTERS_FILE}' не найден.\")\n",
    "         print(f\"Убедитесь, что файл 'algos.csv' находится в папке '{DATA_DIR}'.\")\n",
    "    else:\n",
    "        reconstruct_kainet(DATA_DIR, KNOWN_FILTERS_FILE, OUTPUT_CSV_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428977f",
   "metadata": {},
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631649ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import csv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "# !!! ВАЖНО: Укажите путь к папке с изображениями !!!\n",
    "IMAGE_DIR = './image_archive'  # Замените на ваш путь\n",
    "OUTPUT_CSV_FILE = 'submission.csv'\n",
    "NUM_NEIGHBORS = 6 + 1  # Ищем 6 похожих + 1 (само изображение)\n",
    "# Целевой размер для ResNet50\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "# Пакетная обработка для ускорения извлечения признаков\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def setup_gpu():\n",
    "    \"\"\"Настраивает использование GPU, если доступно.\"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Ограничиваем рост использования памяти GPU\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Ошибки могут возникнуть, если память уже настроена\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"No GPU detected, using CPU.\")\n",
    "\n",
    "def load_feature_extractor():\n",
    "    \"\"\"Загружает предобученную модель ResNet50 для извлечения признаков.\"\"\"\n",
    "    print(\"Загрузка предобученной модели ResNet50...\")\n",
    "    # Загружаем ResNet50 с весами ImageNet, без верхнего слоя (классификатора)\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg',\n",
    "                          input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    # Мы используем выход слоя 'avg_pool' как вектор признаков\n",
    "    # В данном случае base_model уже настроена с GlobalAveragePooling2D (pooling='avg')\n",
    "    print(\"Модель загружена.\")\n",
    "    return base_model\n",
    "\n",
    "def preprocess_image(img_path, target_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    \"\"\"Загружает, изменяет размер и предобрабатывает изображение для ResNet50.\"\"\"\n",
    "    try:\n",
    "        img = keras_image.load_img(img_path, target_size=target_size)\n",
    "        img_array = keras_image.img_to_array(img)\n",
    "        # Добавляем измерение для батча и применяем предобработку ResNet50\n",
    "        img_array_expanded = np.expand_dims(img_array, axis=0)\n",
    "        return preprocess_input(img_array_expanded)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Ошибка при обработке изображения {img_path}: {e}. Пропуск.\")\n",
    "        return None\n",
    "\n",
    "def extract_features_batch(model, image_paths):\n",
    "    \"\"\"Извлекает признаки для пакета изображений.\"\"\"\n",
    "    batch_features = []\n",
    "    valid_indices = []\n",
    "    processed_images = []\n",
    "\n",
    "    for idx, img_path in enumerate(image_paths):\n",
    "        processed = preprocess_image(img_path)\n",
    "        if processed is not None:\n",
    "            processed_images.append(processed[0]) # Убираем измерение батча\n",
    "            valid_indices.append(idx)\n",
    "\n",
    "    if not processed_images:\n",
    "        return np.array([]), [] # Возвращаем пустой массив и пустой список индексов\n",
    "\n",
    "    # Собираем валидные изображения в один батч\n",
    "    batch_array = np.stack(processed_images, axis=0)\n",
    "\n",
    "    # Извлекаем признаки\n",
    "    features = model.predict(batch_array, verbose=0)\n",
    "    return features, valid_indices\n",
    "\n",
    "\n",
    "# --- Main Logic ---\n",
    "\n",
    "def find_similar_images(image_dir, output_csv_file):\n",
    "    \"\"\"\n",
    "    Главная функция для поиска похожих изображений.\n",
    "    \"\"\"\n",
    "    print(\"--- Начало поиска похожих изображений ---\")\n",
    "    setup_gpu()\n",
    "\n",
    "    # 1. Получение списка изображений\n",
    "    try:\n",
    "        all_files = [f for f in os.listdir(image_dir)\n",
    "                     if os.path.isfile(os.path.join(image_dir, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if not all_files:\n",
    "            print(f\"Ошибка: В папке '{image_dir}' не найдено изображений.\")\n",
    "            return\n",
    "        print(f\"Найдено {len(all_files)} изображений.\")\n",
    "        # Сортируем для воспроизводимости порядка\n",
    "        all_files.sort()\n",
    "        image_paths = [os.path.join(image_dir, f) for f in all_files]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Ошибка: Папка '{image_dir}' не найдена.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при чтении директории '{image_dir}': {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Загрузка модели\n",
    "    try:\n",
    "        feature_extractor = load_feature_extractor()\n",
    "    except Exception as e:\n",
    "        print(f\"Критическая ошибка при загрузке модели: {e}\")\n",
    "        print(\"Убедитесь, что TensorFlow установлен и есть доступ к интернету для скачивания весов.\")\n",
    "        return\n",
    "\n",
    "    # 3. Извлечение признаков для всех изображений (пакетная обработка)\n",
    "    print(\"Извлечение признаков из изображений...\")\n",
    "    all_features = []\n",
    "    valid_filenames = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(0, len(image_paths), BATCH_SIZE):\n",
    "        batch_paths = image_paths[i:i+BATCH_SIZE]\n",
    "        batch_filenames = all_files[i:i+BATCH_SIZE]\n",
    "\n",
    "        features, valid_indices = extract_features_batch(feature_extractor, batch_paths)\n",
    "\n",
    "        if features.size > 0:\n",
    "            all_features.append(features)\n",
    "            # Добавляем только имена файлов для успешно обработанных изображений\n",
    "            valid_filenames.extend([batch_filenames[j] for j in valid_indices])\n",
    "\n",
    "        processed_count = len(valid_filenames)\n",
    "        if processed_count > 0:\n",
    "             elapsed = time.time() - start_time\n",
    "             eta = (elapsed / processed_count) * (len(all_files) - processed_count) if processed_count > 0 else 0\n",
    "             print(f\"  Обработано {processed_count}/{len(all_files)} изображений... (ETA: {eta:.1f} сек)\", end='\\r')\n",
    "\n",
    "    print(f\"\\nИзвлечение признаков завершено за {time.time() - start_time:.2f} сек.\")\n",
    "\n",
    "    if not valid_filenames:\n",
    "        print(\"Не удалось извлечь признаки ни из одного изображения.\")\n",
    "        return\n",
    "\n",
    "    # Объединяем признаки из всех батчей\n",
    "    feature_matrix = np.vstack(all_features)\n",
    "    print(f\"Размер итоговой матрицы признаков: {feature_matrix.shape}\")\n",
    "\n",
    "    # 4. Поиск ближайших соседей\n",
    "    print(f\"Поиск {NUM_NEIGHBORS-1} ближайших соседей для каждого изображения...\")\n",
    "    start_time = time.time()\n",
    "    # Используем косинусное расстояние (ближе к 0 = более похожи)\n",
    "    # algorithm='brute' может быть медленным, но точным для косинусного расстояния.\n",
    "    # 'auto' может выбрать 'ball_tree' или 'kd_tree', которые могут быть не оптимальны для косинусной метрики.\n",
    "    # Попробуем 'auto' сначала, если будет медленно, можно переключить на 'brute'.\n",
    "    nn_model = NearestNeighbors(n_neighbors=NUM_NEIGHBORS, metric='cosine', algorithm='auto', n_jobs=-1)\n",
    "    nn_model.fit(feature_matrix)\n",
    "    # Ищем соседей для всех точек в матрице признаков\n",
    "    distances, indices = nn_model.kneighbors(feature_matrix)\n",
    "    print(f\"Поиск соседей завершен за {time.time() - start_time:.2f} сек.\")\n",
    "\n",
    "\n",
    "    # 5. Формирование и сохранение результата\n",
    "    print(f\"Формирование и сохранение результатов в {output_csv_file}...\")\n",
    "    results = []\n",
    "    for i in range(len(valid_filenames)):\n",
    "        query_filename = valid_filenames[i]\n",
    "        neighbor_indices = indices[i]\n",
    "        neighbor_filenames = []\n",
    "        for idx in neighbor_indices:\n",
    "            # Исключаем само изображение из списка соседей\n",
    "            if idx != i:\n",
    "                neighbor_filenames.append(valid_filenames[idx])\n",
    "            # Если набрали нужное количество, выходим (на случай дубликатов или ошибок)\n",
    "            if len(neighbor_filenames) == NUM_NEIGHBORS - 1:\n",
    "                break\n",
    "\n",
    "        # Убедимся, что у нас ровно 6 соседей\n",
    "        if len(neighbor_filenames) != NUM_NEIGHBORS - 1:\n",
    "             warnings.warn(f\"Для файла {query_filename} найдено {len(neighbor_filenames)} соседей вместо {NUM_NEIGHBORS - 1}. \"\n",
    "                           f\"Возможно, есть дубликаты или проблемы с поиском.\")\n",
    "             # Дополняем пустыми строками или повторяем последнего соседа, если нужно (зависит от требований)\n",
    "             # Пока просто оставим как есть, но это может потребовать уточнения.\n",
    "\n",
    "        results.append({\n",
    "            'filename': query_filename,\n",
    "            'ranking': \" \".join(neighbor_filenames)\n",
    "        })\n",
    "\n",
    "    # Запись в CSV\n",
    "    try:\n",
    "        with open(output_csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['filename', 'ranking']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "        print(\"Файл успешно сохранен.\")\n",
    "        print(f\"\\nПример первых строк файла {output_csv_file}:\")\n",
    "        with open(output_csv_file, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i > 5: break # Показываем заголовок + 5 строк данных\n",
    "                print(line.strip())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при сохранении файла {output_csv_file}: {e}\")\n",
    "\n",
    "    print(\"\\n--- Завершение работы ---\")\n",
    "\n",
    "\n",
    "# --- Запуск ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Проверка существования директории с данными\n",
    "    if not os.path.isdir(IMAGE_DIR):\n",
    "         print(f\"Ошибка: Директория с изображениями '{IMAGE_DIR}' не найдена.\")\n",
    "         print(\"Пожалуйста, создайте эту директорию, распакуйте в нее архив\")\n",
    "         print(f\"и измените переменную IMAGE_DIR в скрипте, если нужно.\")\n",
    "    else:\n",
    "        find_similar_images(IMAGE_DIR, OUTPUT_CSV_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
