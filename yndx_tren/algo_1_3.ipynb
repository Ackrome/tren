{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Яндекс. Тренировки по алгоритмам июнь 2021, занятие 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Количество различных чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(set(input().split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Пересечение множеств"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 11 14 17 18 19 2 21 22 23 24 25 27 28 30 35 36 39 43 48 5 51 52 54 55 57 6 61 66 67 68 69 7 70 71 72 73 75 77 78 82 83 84 86 95\n"
     ]
    }
   ],
   "source": [
    "print(*sorted(list(set(map(int,input().split())) & set(map(int,input().split())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Кубики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = list(map(int, input().split()))\n",
    "anya = []\n",
    "borya = []\n",
    "for i in range(n):\n",
    "    anya.append(int(input()))\n",
    "for i in range(m):\n",
    "    borya.append(int(input()))\n",
    "\n",
    "two = sorted(list(set(anya) & set(borya)))\n",
    "print(len(two))\n",
    "print(*two) if len(two) else print()\n",
    "\n",
    "an = sorted(list(set(anya) - set(borya)))\n",
    "print(len(an))\n",
    "print(*an) if len(an) else print()\n",
    "\n",
    "bor = sorted(list(set(borya) - set(anya)))\n",
    "print(len(bor))\n",
    "print(*bor) if len(bor) else print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Количество слов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(len(set(sys.stdin.read().strip().split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. OpenCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "given = set(map(int, input().split()))\n",
    "\n",
    "N = set(map(int, set(input())))\n",
    "\n",
    "print(len(N - given))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "gen1 = list(input())\n",
    "genes1=[]\n",
    "for i in range(len(gen1)-1):\n",
    "  genes1.append(gen1[i]+gen1[i+1])\n",
    "\n",
    "gen2 = list(input())\n",
    "genes2=[]\n",
    "for i in range(len(gen2)-1):\n",
    "  genes2.append(gen2[i]+gen2[i+1])\n",
    "\n",
    "genesis = Counter(genes1)\n",
    "\n",
    "simil = list(set(genes2) & set(genes1))\n",
    "\n",
    "s = 0\n",
    "for i in simil:\n",
    "  s+=genesis[i]\n",
    "\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#G\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m())\n\u001b[0;32m      4\u001b[0m sets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "#G\n",
    "N = int(input())\n",
    "\n",
    "sets = set()\n",
    "for i in range(N):\n",
    "  a, b = map(int,input().split())\n",
    "  if (a+b)==(N-1) and 0<=a<N and 0<=b<N:\n",
    "    sets.add((a,b))\n",
    "\n",
    "print(len(sets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H\n",
    "N = int(input())\n",
    "ses = set()\n",
    "for i in range(N):\n",
    "    x,y = map(int, input().split())\n",
    "    ses.add(x)\n",
    "print(len(ses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I\n",
    "N = int(input())\n",
    "\n",
    "lall = None\n",
    "lany = set()\n",
    "for i in range(N):\n",
    "  m = (int(input()))\n",
    "  studs = set([input() for i in range(m)])\n",
    "\n",
    "  if lall == None:\n",
    "      lall = studs\n",
    "      lany.update(studs)\n",
    "  else:\n",
    "      lall = lall.intersection(studs)\n",
    "      lany.update(studs)\n",
    "      \n",
    "\n",
    "print(len(lall))\n",
    "print(*lall, sep='\\n')\n",
    "print(len(lany))\n",
    "print(*lany,sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#J\n",
    "def extend(rect,d):\n",
    "    \"\"\"Функция нужна для расширения области возможного положения Миши\n",
    "за каждю итерацию изменения координат\n",
    "(на d в каждую сторону)\"\"\"\n",
    "    return rect[0]-d, rect[1]+d,rect[2]-d, rect[3]+d\n",
    "\n",
    "\n",
    "def intersect(rect1,rect2):\n",
    "    \"\"\"Функция нужна для нахожденмя пересечения областей\"\"\"\n",
    "    return max(rect1[0],rect2[0]),min(rect1[1],rect2[1]),max(rect1[2],rect2[2]),min(rect1[3],rect2[3])\n",
    "\n",
    "t,d,n = map(int,input().split())\n",
    "#Рассмотрим возможный диапзон положений нашего Миши как прямоугольник с\n",
    "# 4мя координатами - на каждую из сторон света\n",
    "pos_rect = (0,0,0,0)\n",
    "# координаты можно изменять в + и - в каждую из сторон\n",
    "for _ in range(n):\n",
    "    x, y = map(int, input().split())\n",
    "    pos_rect = extend(pos_rect, t) # Расширяем на t\n",
    "    nav_rect = extend((x + y, x + y, x - y, x - y), d) # Прямоугольник навигатора c учетом погрешности d\n",
    "    pos_rect = intersect(pos_rect, nav_rect) # Находим пересечение\n",
    "\n",
    "\"\"\"\n",
    "После обработки всех сообщений навигатора у нас есть окончательная область возможных позиций Миши,\n",
    "представленная прямоугольником (min_plus, max_plus, min_minus, max_minus).\n",
    "\n",
    "Чтобы найти все возможные точки (x, y) внутри этого прямоугольника:\n",
    "\n",
    "Перебираем все значения x + y от min_plus до max_plus.\n",
    "Перебираем все значения x - y от min_minus до max_minus.\n",
    "Для каждой пары (x + y, x - y) проверяем, что (x1 + y1 + x2 - y2) делится на 2 (это гарантирует целочисленность x и y).\n",
    "Вычисляем координаты (x, y):\n",
    "\"\"\"\n",
    "points = []\n",
    "for x_p_y in range(pos_rect[0], pos_rect[1] + 1): # Перебор x + y\n",
    "    for x_m_y in range(pos_rect[2], pos_rect[3] + 1): # Перебор x - y\n",
    "        if (x_p_y + x_m_y) % 2 == 0: # Проверка целочисленности\n",
    "            x = (x_p_y + x_m_y) // 2\n",
    "            y = x_p_y - x\n",
    "            points.append((x, y))\n",
    "\n",
    "print(len(points))\n",
    "for p in points:\n",
    "    print(*p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model preloaded successfully.\n",
      "\n",
      "--- a/checker.py\n",
      "+++ b/checker.py\n",
      "+import requests\n",
      "+import time\n",
      "+api_token = \"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\"\n",
      "+Model = 'EleutherAI/gpt-neo-125M'\n",
      "+def generate_commit_message_huggingface(diff, api_token):\n",
      "+    \"\"\"\n",
      "+    Генерирует сообщение коммита с использованием Hugging Face API.\n",
      "+    :param diff: Текстовый дифф изменений.\n",
      "+    :param api_token: Ваш API-токен Hugging Face.\n",
      "+    :return: Сгенерированное сообщение коммита.\n",
      "+    \"\"\"\n",
      "+    global Model\n",
      "+    API_URL = f\"https://api-inference.huggingface.co/models/{Model}\"\n",
      "+    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
      "+    prompt = f\"Generate a concise commit message for the following changes:\\n\\n{diff}\"\n",
      "+    payload = {\n",
      "+        \"inputs\": prompt,\n",
      "+        \"parameters\": {\"max_length\": 2048 - len(prompt.split()), \"num_return_sequences\": 1}\n",
      "[...]\n",
      "Response:\n",
      "Generate a concise Git commit message for the following code changes:\n",
      "\n",
      "--- a/checker.py\n",
      "+++ b/checker.py\n",
      "+import requests\n",
      "+import time\n",
      "+api_token = \"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\"\n",
      "+Model = 'EleutherAI/gpt-neo-125M'\n",
      "+def generate_commit_message_huggingface(diff, api_token):\n",
      "+    \"\"\"\n",
      "+    Генерирует сообщение коммита с использованием Hugging Face API.\n",
      "+    :param diff: Текстовый дифф изменений.\n",
      "+    :param api_token: Ваш API-токен Hugging Face.\n",
      "+    :return: Сгенерированное сообщение коммита.\n",
      "+    \"\"\"\n",
      "+    global Model\n",
      "+    API_URL = f\"https://api-inference.huggingface.co/models/{Model}\"\n",
      "+    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
      "+    prompt = f\"Generate a concise commit message for the following changes:\\n\\n{diff}\"\n",
      "+    payload = {\n",
      "+        \"inputs\": prompt,\n",
      "+        \"parameters\": {\"max_length\": 2048 - len(prompt.split()), \"num_return_sequences\": 1}\n",
      "[...]\n",
      "\n",
      "Commit message:\n",
      "+        \"send_reply_to: message with a response to an email.\n",
      "+        \"send_reply_to: message with a reply to an email.\n",
      "+       \"send_reply_to: message with a reply to an email.\n",
      "+      \"send_reply_to: message with a reply to an email.\n",
      "+      \"send_reply_to: message with a reply to an email.\n",
      "+      \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+      \"send_reply_to: message with a reply to an email.\n",
      "+      \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+      \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+      \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a reply to an email.\n",
      "+      \"send_reply_to: message with a reply to an email.\n",
      "+     \"send_reply_to: message with a\n"
     ]
    }
   ],
   "source": [
    "import git\n",
    "import requests\n",
    "import time\n",
    "\n",
    "api_token = \"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\"\n",
    "#Model = 'EleutherAI/gpt-neo-125M'\n",
    "Model = 'distilgpt2'\n",
    "#Model = 'google-t5/t5-small'\n",
    "#Model = 'EleutherAI/gpt-neo-2.7B'\n",
    "#Model = 'EleutherAI/gpt-neo-1.3B'\n",
    "\n",
    "\n",
    "    \n",
    "def preload_model(api_token):\n",
    "    \"\"\"\n",
    "    Предварительно загружает модель, чтобы она была готова к использованию.\n",
    "    \n",
    "    :param api_token: Ваш API-токен Hugging Face.\n",
    "    \"\"\"\n",
    "    API_URL = f\"https://api-inference.huggingface.co/models/{Model}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
    "    payload = {\n",
    "        \"inputs\": \"Test input to preload the model.\",\n",
    "        \"parameters\": {\"max_length\": 10}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Model preloaded successfully.\")\n",
    "        else:\n",
    "            print(f\"Preloading failed: {response.status_code}, {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preloading: {e}\")\n",
    "\n",
    "\n",
    "def generate_commit_message_with_retries(diff, api_token, retries=5, delay=5):\n",
    "    global model\n",
    "    \"\"\"\n",
    "    Генерирует сообщение коммита с повторными попытками в случае ошибки.\n",
    "    \n",
    "    :param diff: Текстовый дифф изменений.\n",
    "    :param api_token: Ваш API-токен Hugging Face.\n",
    "    :param retries: Количество попыток.\n",
    "    :param delay: Задержка между попытками (в секундах).\n",
    "    :return: Сгенерированное сообщение коммита.\n",
    "    \"\"\"\n",
    "    API_URL = f\"https://api-inference.huggingface.co/models/{Model}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
    "    \n",
    "    #prompt = f\"Generate a concise commit message for the following changes:\\n\\n{diff}\"\n",
    "    prompt = f\"Generate a concise Git commit message for the following code changes:\\n\\n{diff}\\n\\nCommit message:\"\n",
    "    \n",
    "    payload = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_length\": min(2048, len(prompt.split()) + 50),  # Ограничиваем длину ответа\n",
    "        \"num_return_sequences\": 1,\n",
    "        \"temperature\": 0.7,  # Контролирует случайность генерации\n",
    "        \"top_p\": 0.9         # Фильтрует менее вероятные токены\n",
    "    }\n",
    "}\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.post(API_URL, headers=headers, json=payload)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                print('Response:')\n",
    "                return response.json()[0]['generated_text']\n",
    "            elif response.status_code == 503:\n",
    "                error_data = response.json()\n",
    "                estimated_time = error_data.get(\"estimated_time\", delay)\n",
    "                print(f\"Model is loading. Retrying in {estimated_time} seconds...\")\n",
    "                time.sleep(estimated_time)\n",
    "            else:\n",
    "                raise Exception(f\"Error: {response.status_code}, {response.text}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                raise Exception(\"All attempts failed.\")\n",
    "            \n",
    "\n",
    "def get_git_diff(repo_path):\n",
    "    \"\"\"\n",
    "    Получает дифф между текущим состоянием рабочего каталога и последним коммитом.\n",
    "    \n",
    "    :param repo_path: Путь к локальному репозиторию.\n",
    "    :return: Строка с диффом.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Открываем репозиторий\n",
    "        repo = git.Repo(repo_path)\n",
    "        \n",
    "        # Проверяем, есть ли изменения\n",
    "        if not repo.is_dirty():\n",
    "            return \"No changes detected in the repository.\"\n",
    "        \n",
    "        # Получаем дифф относительно HEAD\n",
    "        diff = repo.git.diff('HEAD')\n",
    "        return diff\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "\n",
    "def filter_diff(diff):\n",
    "    \"\"\"\n",
    "    Фильтрует дифф, оставляя только добавленные и удаленные строки.\n",
    "    \n",
    "    :param diff: Текстовый дифф.\n",
    "    :return: Отфильтрованный дифф.\n",
    "    \"\"\"\n",
    "    filtered_lines = []\n",
    "    for line in diff.split('\\n'):\n",
    "        if line.startswith('+') or line.startswith('-'):\n",
    "            # Исключаем строки, которые содержат только пробелы или закомментированный код\n",
    "            if not line.strip().startswith('#') and len(line.strip()) > 1:\n",
    "                filtered_lines.append(line)\n",
    "    return '\\n'.join(filtered_lines)\n",
    "\n",
    "\n",
    "def shorten_diff(diff, max_lines=20):\n",
    "    \"\"\"\n",
    "    Сокращает дифф до указанного количества строк.\n",
    "    \n",
    "    :param diff: Текстовый дифф.\n",
    "    :param max_lines: Максимальное количество строк.\n",
    "    :return: Сокращенный дифф.\n",
    "    \"\"\"\n",
    "    lines = diff.split('\\n')\n",
    "    if len(lines) > max_lines:\n",
    "        return '\\n'.join(lines[:max_lines]) + \"\\n[...]\"\n",
    "    return diff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preload_model(api_token)\n",
    "\n",
    "repo_path = r'C:\\Users\\ivant\\Desktop\\tren'\n",
    "diff = get_git_diff(repo_path)\n",
    "diff = filter_diff(diff)\n",
    "diff = shorten_diff(diff)\n",
    "#print('\\n'+diff)\n",
    "\n",
    "commit_message = generate_commit_message_with_retries(diff, api_token)\n",
    "print(commit_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
